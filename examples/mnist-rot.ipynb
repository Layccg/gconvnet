{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rasmusj/code\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow.train\n",
    "from tensorflow.keras import layers\n",
    "from gconvnet import GConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.14.0\n",
      "Keras      version: 2.2.4-tf\n",
      "Numpy version:      1.16.4\n",
      "Matplotlib version: 3.1.0\n",
      "Python version:     3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "print('Tensorflow version: {}'.format(tf.__version__))\n",
    "print('Keras      version: {}'.format(tf.keras.__version__))\n",
    "print('Numpy version:      {}'.format(np.__version__))\n",
    "print('Matplotlib version: {}'.format(matplotlib.__version__))\n",
    "print('Python version:     {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the MNIST data. It is organized as follows:\n",
    "* Each samples is represented as 785 scalars. The first 24*24=784 are the pixel values. The last is the label.\n",
    "* mnist_train.amat contains 12,000 samples. The first 10,000 are training samples, the last 2000 are validation samples.\n",
    "* mnist_test.amat contains 50,000 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 10000 \n",
    "val_n = 2000\n",
    "test_n = 50000\n",
    "sample_width = 28\n",
    "sample_height = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_val_data = np.loadtxt('gconvnet/examples/mnist_all_rotation_normalized_float_train_valid.amat')\n",
    "raw_test_data = np.loadtxt('gconvnet/examples/mnist_all_rotation_normalized_float_test.amat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert raw_train_val_data.shape[0] == train_n + val_n, \\\n",
    "       'mnist_train.amat had unexpected number of samples'\n",
    "assert raw_test_data.shape[0] == test_n, \\\n",
    "       'mnist_test.amat had unexpected number of samples'\n",
    "\n",
    "assert raw_train_val_data.shape[1] == sample_width*sample_height + 1, \\\n",
    "    \"mnist_train.amat samples have wrong size, expected {0} got {1}\".format(\n",
    "           sample_width*sample_height+1, raw_train_val_data.shape[1])\n",
    "assert raw_test_data.shape[1] == sample_width*sample_height + 1, \\\n",
    "    \"mnist_test.amat samples have wrong size, expected {0} got {1}\".format(\n",
    "           sample_width*sample_height+1, raw_test_data.shape[1])\n",
    "\n",
    "train_x = raw_train_val_data[:train_n,:-1].reshape(train_n,sample_width,sample_height,1,1)\n",
    "train_y = raw_train_val_data[:train_n,-1]\n",
    "\n",
    "val_x = raw_train_val_data[train_n:,:-1].reshape(val_n,sample_width,sample_height,1,1)\n",
    "val_y = raw_train_val_data[train_n:,-1]\n",
    "\n",
    "test_x = raw_test_data[:,:-1].reshape(test_n,sample_width,sample_height,1,1)\n",
    "test_y = raw_test_data[:,-1]\n",
    "\n",
    "train_data = {\n",
    "    'x' : train_x,\n",
    "    'y' : train_y,\n",
    "    'y_cat' : tf.keras.utils.to_categorical(train_y,10),\n",
    "    'name' : 'train',\n",
    "    'n' : train_n}\n",
    "test_data = {\n",
    "    'x' : test_x,\n",
    "    'y' : test_y,\n",
    "    'y_cat' : tf.keras.utils.to_categorical(test_y,10),\n",
    "    'name' : 'test',\n",
    "    'n' : test_n}\n",
    "val_data = {\n",
    "    'x' : val_x,\n",
    "    'y' : val_y,\n",
    "    'y_cat' : tf.keras.utils.to_categorical(val_y,10),\n",
    "    'name' : 'validation',\n",
    "    'n' : val_n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset sample #6611 with label: 3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_to_inspect = train_data\n",
    "example_idx = -1 # index of sample to inspect. -1 for random.\n",
    "\n",
    "if example_idx == -1:\n",
    "    example_idx = random.randint(0,dataset_to_inspect['n']-1)\n",
    "\n",
    "assert (example_idx >= 0 and example_idx < dataset_to_inspect['n']-1), \\\n",
    "    'Example index out of bounds'\n",
    "\n",
    "example_x = dataset_to_inspect['x'][example_idx].reshape(sample_width,sample_height)\n",
    "example_y = dataset_to_inspect['y'][example_idx]\n",
    "\n",
    "plt.imshow(example_x)\n",
    "\n",
    "print('{0} dataset sample #{1} with label: {2}'.format(\n",
    "    dataset_to_inspect['name'].capitalize(), example_idx, example_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 1 1\n",
      "-1 1 1\n",
      "Applying GConv1\n",
      "Input shape: (?, 28, 28, 1, 1)\n",
      "Filtershape: (3, 3, 1, 1, 4, 30)\n",
      "Output shape: (?, 26, 26, 120)\n",
      "Output shape: (?, 26, 26, 4, 30)\n",
      "-1 1 1\n",
      "-1 1 1\n",
      "Applying GConv2\n",
      "Input shape: (?, 26, 26, 4, 30)\n",
      "Filtershape: (3, 3, 4, 30, 4, 30)\n",
      "Output shape: (?, 24, 24, 120)\n",
      "Output shape: (?, 24, 24, 4, 30)\n",
      "-1 1 1\n",
      "-1 1 1\n",
      "Applying GConv3\n",
      "Input shape: (?, 24, 24, 4, 30)\n",
      "Filtershape: (3, 3, 4, 30, 4, 30)\n",
      "Output shape: (?, 22, 22, 120)\n",
      "Output shape: (?, 22, 22, 4, 30)\n",
      "-1 1 1\n",
      "-1 1 1\n",
      "Applying GConv4\n",
      "Input shape: (?, 22, 22, 4, 30)\n",
      "Filtershape: (3, 3, 4, 30, 4, 30)\n",
      "Output shape: (?, 20, 20, 120)\n",
      "Output shape: (?, 20, 20, 4, 30)\n"
     ]
    }
   ],
   "source": [
    "custommodel = keras.Sequential()\n",
    "custommodel.add(GConv2D(30, \n",
    "                        kernel_size=(3,3),\n",
    "                        input_shape=(28,28,1,1),\n",
    "                        G = 'c4',\n",
    "                        G_action = 'rot90',\n",
    "                        activation='relu',\n",
    "                        use_bias = False,\n",
    "                        name='GConv1'))\n",
    "custommodel.add(GConv2D(30,\n",
    "                       kernel_size=(3,3),\n",
    "                       G='c4',\n",
    "                       G_action = 'rot90',\n",
    "                       activation='relu',\n",
    "                       use_bias=False,\n",
    "                       name='GConv2'))\n",
    "custommodel.add(GConv2D(30,\n",
    "                       kernel_size=(3,3),\n",
    "                       G='c4',\n",
    "                       G_action = 'rot90',\n",
    "                       activation='relu',\n",
    "                       use_bias=False,\n",
    "                       name='GConv3'))\n",
    "custommodel.add(GConv2D(30,\n",
    "                       kernel_size=(3,3),\n",
    "                       G='c4',\n",
    "                       G_action = 'rot90',\n",
    "                       activation='relu',\n",
    "                       use_bias=False,\n",
    "                       name='GConv4'))\n",
    "custommodel.add(layers.Flatten())\n",
    "custommodel.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "GConv1 (GConv2D)             (None, 26, 26, 4, 30)     270       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 81120)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                811210    \n",
      "=================================================================\n",
      "Total params: 811,480\n",
      "Trainable params: 811,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custommodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "custommodel.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10000/10000 [==============================] - 4s 436us/sample - loss: 1.0854 - acc: 0.6339\n",
      "Epoch 2/25\n",
      "10000/10000 [==============================] - 4s 387us/sample - loss: 0.4753 - acc: 0.8522\n",
      "Epoch 3/25\n",
      "10000/10000 [==============================] - 4s 390us/sample - loss: 0.2843 - acc: 0.9097\n",
      "Epoch 4/25\n",
      "10000/10000 [==============================] - 4s 390us/sample - loss: 0.1596 - acc: 0.9483\n",
      "Epoch 5/25\n",
      "10000/10000 [==============================] - 4s 390us/sample - loss: 0.0869 - acc: 0.9687\n",
      "Epoch 6/25\n",
      "10000/10000 [==============================] - 4s 390us/sample - loss: 0.0599 - acc: 0.9789\n",
      "Epoch 7/25\n",
      "10000/10000 [==============================] - 4s 391us/sample - loss: 0.0275 - acc: 0.9906\n",
      "Epoch 8/25\n",
      "10000/10000 [==============================] - 4s 392us/sample - loss: 0.0359 - acc: 0.9868\n",
      "Epoch 9/25\n",
      "10000/10000 [==============================] - 4s 405us/sample - loss: 0.0250 - acc: 0.9906\n",
      "Epoch 10/25\n",
      "10000/10000 [==============================] - 4s 401us/sample - loss: 0.0193 - acc: 0.9927\n",
      "Epoch 11/25\n",
      "10000/10000 [==============================] - 4s 412us/sample - loss: 0.0130 - acc: 0.9958\n",
      "Epoch 12/25\n",
      "10000/10000 [==============================] - 4s 409us/sample - loss: 0.0225 - acc: 0.9914\n",
      "Epoch 13/25\n",
      "10000/10000 [==============================] - 4s 407us/sample - loss: 0.0161 - acc: 0.9942\n",
      "Epoch 14/25\n",
      "10000/10000 [==============================] - 4s 407us/sample - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 15/25\n",
      "10000/10000 [==============================] - 4s 407us/sample - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 16/25\n",
      "10000/10000 [==============================] - 4s 407us/sample - loss: 0.0047 - acc: 0.9983\n",
      "Epoch 17/25\n",
      "10000/10000 [==============================] - 4s 408us/sample - loss: 0.0030 - acc: 0.9988\n",
      "Epoch 18/25\n",
      "10000/10000 [==============================] - 4s 408us/sample - loss: 0.0174 - acc: 0.9949\n",
      "Epoch 19/25\n",
      "10000/10000 [==============================] - 4s 407us/sample - loss: 0.0249 - acc: 0.9919\n",
      "Epoch 20/25\n",
      "10000/10000 [==============================] - 4s 415us/sample - loss: 0.0108 - acc: 0.9965\n",
      "Epoch 21/25\n",
      "10000/10000 [==============================] - 4s 417us/sample - loss: 0.0067 - acc: 0.9977\n",
      "Epoch 22/25\n",
      "10000/10000 [==============================] - 4s 413us/sample - loss: 0.0070 - acc: 0.9981\n",
      "Epoch 23/25\n",
      "10000/10000 [==============================] - 4s 411us/sample - loss: 0.0057 - acc: 0.9979\n",
      "Epoch 24/25\n",
      "10000/10000 [==============================] - 4s 418us/sample - loss: 0.0074 - acc: 0.9976\n",
      "Epoch 25/25\n",
      "10000/10000 [==============================] - 4s 417us/sample - loss: 0.0275 - acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1b27dcc550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custommodel.fit(\n",
    "    train_data['x'],\n",
    "    train_data['y_cat'],\n",
    "    batch_size=128,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 253us/sample - loss: 0.8521 - acc: 0.8930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8521332949176431, 0.893]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custommodel.evaluate(val_data['x'],val_data['y_cat'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
