{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rasmusj/code\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow.train\n",
    "from tensorflow.keras import layers\n",
    "from gconvnet import GConv2D, GMaxPool,ForgetAction,RememberAction\n",
    "import gconvnet.groups as groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.14.0\n",
      "Keras      version: 2.2.4-tf\n",
      "Numpy version:      1.16.4\n",
      "Matplotlib version: 3.1.0\n",
      "Python version:     3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "print('Tensorflow version: {}'.format(tf.__version__))\n",
    "print('Keras      version: {}'.format(tf.keras.__version__))\n",
    "print('Numpy version:      {}'.format(np.__version__))\n",
    "print('Matplotlib version: {}'.format(matplotlib.__version__))\n",
    "print('Python version:     {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the MNIST data. It is organized as follows:\n",
    "* Each samples is represented as 785 scalars. The first 24*24=784 are the pixel values. The last is the label.\n",
    "* mnist_train.amat contains 12,000 samples. The first 10,000 are training samples, the last 2000 are validation samples.\n",
    "* mnist_test.amat contains 50,000 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 10000 \n",
    "val_n = 2000\n",
    "test_n = 50000\n",
    "sample_width = 28\n",
    "sample_height = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_val_data = np.loadtxt('gconvnet/examples/mnist_all_rotation_normalized_float_train_valid.amat')\n",
    "raw_test_data = np.loadtxt('gconvnet/examples/mnist_all_rotation_normalized_float_test.amat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert raw_train_val_data.shape[0] == train_n + val_n, \\\n",
    "       'mnist_train.amat had unexpected number of samples'\n",
    "assert raw_test_data.shape[0] == test_n, \\\n",
    "       'mnist_test.amat had unexpected number of samples'\n",
    "\n",
    "assert raw_train_val_data.shape[1] == sample_width*sample_height + 1, \\\n",
    "    \"mnist_train.amat samples have wrong size, expected {0} got {1}\".format(\n",
    "           sample_width*sample_height+1, raw_train_val_data.shape[1])\n",
    "assert raw_test_data.shape[1] == sample_width*sample_height + 1, \\\n",
    "    \"mnist_test.amat samples have wrong size, expected {0} got {1}\".format(\n",
    "           sample_width*sample_height+1, raw_test_data.shape[1])\n",
    "\n",
    "train_x = raw_train_val_data[:train_n,:-1].reshape(train_n,sample_width,sample_height,1,1)\n",
    "train_y = raw_train_val_data[:train_n,-1]\n",
    "\n",
    "val_x = raw_train_val_data[train_n:,:-1].reshape(val_n,sample_width,sample_height,1,1)\n",
    "val_y = raw_train_val_data[train_n:,-1]\n",
    "\n",
    "test_x = raw_test_data[:,:-1].reshape(test_n,sample_width,sample_height,1,1)\n",
    "test_y = raw_test_data[:,-1]\n",
    "\n",
    "train_data = {\n",
    "    'x' : train_x,\n",
    "    'y' : train_y,\n",
    "    'y_cat' : tf.keras.utils.to_categorical(train_y,10),\n",
    "    'name' : 'train',\n",
    "    'n' : train_n}\n",
    "test_data = {\n",
    "    'x' : test_x,\n",
    "    'y' : test_y,\n",
    "    'y_cat' : tf.keras.utils.to_categorical(test_y,10),\n",
    "    'name' : 'test',\n",
    "    'n' : test_n}\n",
    "val_data = {\n",
    "    'x' : val_x,\n",
    "    'y' : val_y,\n",
    "    'y_cat' : tf.keras.utils.to_categorical(val_y,10),\n",
    "    'name' : 'validation',\n",
    "    'n' : val_n}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset sample #6956 with label: 6.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_to_inspect = train_data\n",
    "example_idx = -1 # index of sample to inspect. -1 for random.\n",
    "\n",
    "if example_idx == -1:\n",
    "    example_idx = random.randint(0,dataset_to_inspect['n']-1)\n",
    "\n",
    "assert (example_idx >= 0 and example_idx < dataset_to_inspect['n']-1), \\\n",
    "    'Example index out of bounds'\n",
    "\n",
    "example_x = dataset_to_inspect['x'][example_idx].reshape(sample_width,sample_height)\n",
    "example_y = dataset_to_inspect['y'][example_idx]\n",
    "\n",
    "plt.imshow(example_x)\n",
    "\n",
    "print('{0} dataset sample #{1} with label: {2}'.format(\n",
    "    dataset_to_inspect['name'].capitalize(), example_idx, example_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4_full_subgroup= groups.create_inclusion(groups.d4, list(range(8)))\n",
    "\n",
    "p4cnn_rp = keras.Sequential()\n",
    "p4cnn_rp.add(GConv2D(20,\n",
    "                     kernel_size=(3,3),\n",
    "                     input_shape=(28,28,1,1),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv1'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "p4cnn_rp.add(GConv2D(20,\n",
    "                     kernel_size=(3,3),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv2'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "p4cnn_rp.add(ForgetAction())\n",
    "p4cnn_rp.add(layers.MaxPool2D())\n",
    "p4cnn_rp.add(RememberAction('trivial'))\n",
    "\n",
    "\n",
    "\n",
    "p4cnn_rp.add(GConv2D(20,\n",
    "                     kernel_size=(3,3),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv3'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "\n",
    "p4cnn_rp.add(GConv2D(20,\n",
    "                     kernel_size=(3,3),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv4'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "\n",
    "p4cnn_rp.add(GConv2D(20,\n",
    "                     kernel_size=(3,3),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv5'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "\n",
    "p4cnn_rp.add(GConv2D(20,\n",
    "                     kernel_size=(3,3),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv6'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "\n",
    "p4cnn_rp.add(GConv2D(10,\n",
    "                     kernel_size=(3,3),\n",
    "                     G = 'd4',\n",
    "                     G_action = 'd4',\n",
    "                     activation='relu',\n",
    "                     use_bias = False,\n",
    "                     name='GConv7'))\n",
    "p4cnn_rp.add(layers.BatchNormalization())\n",
    "p4cnn_rp.add(GMaxPool(d4_full_subgroup))\n",
    "\n",
    "\n",
    "p4cnn_rp.add(layers.Flatten())\n",
    "p4cnn_rp.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p4cnn = keras.Sequential()\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  input_shape=(28,28,1,1),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv1'))\n",
    "p4cnn.add(layers.BatchNormalization())\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv2'))\n",
    "p4cnn.add(layers.BatchNormalization())\n",
    "p4cnn.add(ForgetAction())\n",
    "p4cnn.add(layers.MaxPool2D())\n",
    "p4cnn.add(RememberAction('d4'))\n",
    "\n",
    "\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv3'))\n",
    "p4cnn.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv4'))\n",
    "p4cnn.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv5'))\n",
    "p4cnn.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv6'))\n",
    "p4cnn.add(layers.BatchNormalization())\n",
    "\n",
    "p4cnn.add(GConv2D(10,\n",
    "                  kernel_size=(3,3),\n",
    "                  G = 'd4',\n",
    "                  G_action = 'd4',\n",
    "                  activation='relu',\n",
    "                  use_bias = False,\n",
    "                  name='GConv7'))\n",
    "\n",
    "p4cnn.add(layers.Flatten())\n",
    "p4cnn.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "GConv1 (GConv2D)             (None, 26, 26, 8, 10)     90        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 26, 26, 8, 10)     40        \n",
      "_________________________________________________________________\n",
      "GConv2 (GConv2D)             (None, 24, 24, 8, 10)     7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 24, 24, 8, 10)     40        \n",
      "_________________________________________________________________\n",
      "forget_action_1 (ForgetActio (None, 24, 24, 80)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 80)        0         \n",
      "_________________________________________________________________\n",
      "remember_action_1 (RememberA (None, 12, 12, 8, 10)     0         \n",
      "_________________________________________________________________\n",
      "GConv3 (GConv2D)             (None, 10, 10, 8, 10)     7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 10, 8, 10)     40        \n",
      "_________________________________________________________________\n",
      "GConv4 (GConv2D)             (None, 8, 8, 8, 10)       7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 8, 10)       40        \n",
      "_________________________________________________________________\n",
      "GConv5 (GConv2D)             (None, 6, 6, 8, 10)       7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 6, 6, 8, 10)       40        \n",
      "_________________________________________________________________\n",
      "GConv6 (GConv2D)             (None, 4, 4, 8, 10)       7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 8, 10)       40        \n",
      "_________________________________________________________________\n",
      "GConv7 (GConv2D)             (None, 2, 2, 8, 10)       7200      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                3210      \n",
      "=================================================================\n",
      "Total params: 46,740\n",
      "Trainable params: 46,620\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p4cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4cnn.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "p4cnn_rp.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10000/10000 [==============================] - 5s 477us/sample - loss: 1.2226 - acc: 0.5887\n",
      "Epoch 2/25\n",
      "10000/10000 [==============================] - 3s 325us/sample - loss: 0.4319 - acc: 0.8656\n",
      "Epoch 3/25\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.2893 - acc: 0.9089\n",
      "Epoch 4/25\n",
      "10000/10000 [==============================] - 3s 331us/sample - loss: 0.1992 - acc: 0.9360\n",
      "Epoch 5/25\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.1675 - acc: 0.9479\n",
      "Epoch 6/25\n",
      "10000/10000 [==============================] - 3s 332us/sample - loss: 0.1466 - acc: 0.9502\n",
      "Epoch 7/25\n",
      "10000/10000 [==============================] - 3s 326us/sample - loss: 0.1115 - acc: 0.9619\n",
      "Epoch 8/25\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.1005 - acc: 0.9678\n",
      "Epoch 9/25\n",
      "10000/10000 [==============================] - 3s 332us/sample - loss: 0.0894 - acc: 0.9692\n",
      "Epoch 10/25\n",
      "10000/10000 [==============================] - 3s 329us/sample - loss: 0.0621 - acc: 0.9798\n",
      "Epoch 11/25\n",
      "10000/10000 [==============================] - 3s 332us/sample - loss: 0.0510 - acc: 0.9822\n",
      "Epoch 12/25\n",
      "10000/10000 [==============================] - 3s 335us/sample - loss: 0.0558 - acc: 0.9810\n",
      "Epoch 13/25\n",
      "10000/10000 [==============================] - 3s 331us/sample - loss: 0.0592 - acc: 0.9787\n",
      "Epoch 14/25\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.0368 - acc: 0.9882\n",
      "Epoch 15/25\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 0.0322 - acc: 0.9901\n",
      "Epoch 16/25\n",
      "10000/10000 [==============================] - 3s 329us/sample - loss: 0.0123 - acc: 0.9971\n",
      "Epoch 17/25\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0084 - acc: 0.9983\n",
      "Epoch 18/25\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.0091 - acc: 0.9988\n",
      "Epoch 19/25\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0514 - acc: 0.9818\n",
      "Epoch 20/25\n",
      "10000/10000 [==============================] - 3s 331us/sample - loss: 0.0572 - acc: 0.9806\n",
      "Epoch 21/25\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0493 - acc: 0.9826\n",
      "Epoch 22/25\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0489 - acc: 0.9821\n",
      "Epoch 23/25\n",
      "10000/10000 [==============================] - 3s 333us/sample - loss: 0.0239 - acc: 0.9934\n",
      "Epoch 24/25\n",
      "10000/10000 [==============================] - 3s 328us/sample - loss: 0.0080 - acc: 0.9983\n",
      "Epoch 25/25\n",
      "10000/10000 [==============================] - 3s 327us/sample - loss: 0.0029 - acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f41cb4bc320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4cnn.fit(\n",
    "    train_data['x'],\n",
    "    train_data['y_cat'],\n",
    "    batch_size=128,\n",
    "    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 231us/sample - loss: 0.2636 - acc: 0.9435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26358294396847487, 0.9435]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4cnn.evaluate(val_data['x'],val_data['y_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10000/10000 [==============================] - 8s 847us/sample - loss: 1.8055 - acc: 0.3673\n",
      "Epoch 2/25\n",
      "10000/10000 [==============================] - 8s 762us/sample - loss: 0.8501 - acc: 0.7328\n",
      "Epoch 3/25\n",
      "10000/10000 [==============================] - 8s 764us/sample - loss: 0.4502 - acc: 0.8613\n",
      "Epoch 4/25\n",
      "10000/10000 [==============================] - 8s 767us/sample - loss: 0.3263 - acc: 0.9001\n",
      "Epoch 5/25\n",
      "10000/10000 [==============================] - 8s 776us/sample - loss: 0.2650 - acc: 0.9215\n",
      "Epoch 6/25\n",
      "10000/10000 [==============================] - 8s 791us/sample - loss: 0.2209 - acc: 0.9294\n",
      "Epoch 7/25\n",
      "10000/10000 [==============================] - 8s 770us/sample - loss: 0.1960 - acc: 0.9384\n",
      "Epoch 8/25\n",
      "10000/10000 [==============================] - 8s 756us/sample - loss: 0.1743 - acc: 0.9434\n",
      "Epoch 9/25\n",
      "10000/10000 [==============================] - 8s 758us/sample - loss: 0.1558 - acc: 0.9490\n",
      "Epoch 10/25\n",
      "10000/10000 [==============================] - 8s 759us/sample - loss: 0.1436 - acc: 0.9528\n",
      "Epoch 11/25\n",
      "10000/10000 [==============================] - 8s 760us/sample - loss: 0.1209 - acc: 0.9605\n",
      "Epoch 12/25\n",
      "10000/10000 [==============================] - 8s 758us/sample - loss: 0.1092 - acc: 0.9644\n",
      "Epoch 13/25\n",
      "10000/10000 [==============================] - 8s 762us/sample - loss: 0.1112 - acc: 0.9618\n",
      "Epoch 14/25\n",
      "10000/10000 [==============================] - 8s 774us/sample - loss: 0.0936 - acc: 0.9715\n",
      "Epoch 15/25\n",
      "10000/10000 [==============================] - 8s 781us/sample - loss: 0.0886 - acc: 0.9716\n",
      "Epoch 16/25\n",
      "10000/10000 [==============================] - 8s 799us/sample - loss: 0.0894 - acc: 0.9696\n",
      "Epoch 17/25\n",
      "10000/10000 [==============================] - 8s 790us/sample - loss: 0.0720 - acc: 0.9757\n",
      "Epoch 18/25\n",
      "10000/10000 [==============================] - 8s 788us/sample - loss: 0.0702 - acc: 0.9772\n",
      "Epoch 19/25\n",
      "10000/10000 [==============================] - 8s 786us/sample - loss: 0.0587 - acc: 0.9814\n",
      "Epoch 20/25\n",
      "10000/10000 [==============================] - 8s 783us/sample - loss: 0.0559 - acc: 0.9818\n",
      "Epoch 21/25\n",
      "10000/10000 [==============================] - 8s 786us/sample - loss: 0.0596 - acc: 0.9794\n",
      "Epoch 22/25\n",
      "10000/10000 [==============================] - 8s 783us/sample - loss: 0.0511 - acc: 0.9830\n",
      "Epoch 23/25\n",
      "10000/10000 [==============================] - 8s 785us/sample - loss: 0.0513 - acc: 0.9827\n",
      "Epoch 24/25\n",
      "10000/10000 [==============================] - 8s 786us/sample - loss: 0.0469 - acc: 0.9832\n",
      "Epoch 25/25\n",
      " 2624/10000 [======>.......................] - ETA: 5s - loss: 0.0504 - acc: 0.9809"
     ]
    }
   ],
   "source": [
    "p4cnn_rp.fit(\n",
    "    train_data['x'],\n",
    "    train_data['y_cat'],\n",
    "    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "GConv1 (GConv2D)             (None, 26, 26, 8, 20)     180       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 8, 20)     80        \n",
      "_________________________________________________________________\n",
      "g_max_pool (GMaxPool)        (None, 26, 26, 1, 20)     0         \n",
      "_________________________________________________________________\n",
      "GConv2 (GConv2D)             (None, 24, 24, 8, 20)     3600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 8, 20)     80        \n",
      "_________________________________________________________________\n",
      "g_max_pool_1 (GMaxPool)      (None, 24, 24, 1, 20)     0         \n",
      "_________________________________________________________________\n",
      "forget_action (ForgetAction) (None, 24, 24, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "remember_action (RememberAct (None, 12, 12, 8, 2)      0         \n",
      "_________________________________________________________________\n",
      "GConv3 (GConv2D)             (None, 10, 10, 8, 20)     2880      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 8, 20)     80        \n",
      "_________________________________________________________________\n",
      "g_max_pool_2 (GMaxPool)      (None, 10, 10, 1, 20)     0         \n",
      "_________________________________________________________________\n",
      "GConv4 (GConv2D)             (None, 8, 8, 8, 20)       3600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 8, 20)       80        \n",
      "_________________________________________________________________\n",
      "g_max_pool_3 (GMaxPool)      (None, 8, 8, 1, 20)       0         \n",
      "_________________________________________________________________\n",
      "GConv5 (GConv2D)             (None, 6, 6, 8, 20)       3600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 8, 20)       80        \n",
      "_________________________________________________________________\n",
      "g_max_pool_4 (GMaxPool)      (None, 6, 6, 1, 20)       0         \n",
      "_________________________________________________________________\n",
      "GConv6 (GConv2D)             (None, 4, 4, 8, 20)       3600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 8, 20)       80        \n",
      "_________________________________________________________________\n",
      "g_max_pool_5 (GMaxPool)      (None, 4, 4, 1, 20)       0         \n",
      "_________________________________________________________________\n",
      "GConv7 (GConv2D)             (None, 2, 2, 8, 10)       1800      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 8, 10)       40        \n",
      "_________________________________________________________________\n",
      "g_max_pool_6 (GMaxPool)      (None, 2, 2, 1, 10)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 20,190\n",
      "Trainable params: 19,930\n",
      "Non-trainable params: 260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p4cnn_rp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
